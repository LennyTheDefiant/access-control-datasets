{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"/kaggle/input/combineddata/combinedBalancedDataset.csv\", header = None, delimiter = ',')\n",
    "\n",
    "X = dataset.drop(columns = [26,27,28,29])\n",
    "y = dataset.filter([26,27,28,29])\n",
    "print(X,y)\n",
    "\n",
    "unique_rows = np.unique(y, axis=0).tolist()\n",
    "print(unique_rows)\n",
    "\n",
    "y['combined']= y.values.tolist()\n",
    "y = y.drop(columns = [26,27,28,29])\n",
    "print(y)\n",
    "print(y.shape)\n",
    "#merges mutliple targets into single multiclassfication for y\n",
    "i = 0\n",
    "while i < len(y):\n",
    "    j = 0\n",
    "    while j < len(unique_rows):\n",
    "        if y.loc[y.index[i],'combined'] == unique_rows[j]:\n",
    "            y.loc[y.index[i],'combined'] = unique_rows.index(unique_rows[j])\n",
    "        j +=1\n",
    "    i+=1\n",
    "    \n",
    "y['combined'] = y['combined'].astype(int)\n",
    "\n",
    "y.to_numpy()\n",
    "\n",
    "print(y)\n",
    "\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"done\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# Convert y to 1-dimensional array\n",
    "y_labels = np.argmax(y.values, axis=1)\n",
    "\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "max_score_SMOTE = 0\n",
    "best_params_SMOTE = {}\n",
    "\n",
    "# Perform grid search for best parameters for the SMOTE dataset\n",
    "for n_estimators in param_grid['n_estimators']:\n",
    "    for max_depth in param_grid['max_depth']:\n",
    "        for min_samples_split in param_grid['min_samples_split']:\n",
    "            for min_samples_leaf in param_grid['min_samples_leaf']:\n",
    "                for max_features in param_grid['max_features']:\n",
    "                    params = {\n",
    "                        'n_estimators': n_estimators,\n",
    "                        'max_depth': max_depth,\n",
    "                        'min_samples_split': min_samples_split,\n",
    "                        'min_samples_leaf': min_samples_leaf,\n",
    "                        'max_features': max_features\n",
    "                    }\n",
    "                    forest_SMOTE = RandomForestClassifier(**params)\n",
    "                    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "                    scores2 = cross_val_score(forest_SMOTE, x_train2, y_train2, cv=skf)\n",
    "                    score_mean2 = scores2.mean()\n",
    "                    if score_mean2 > max_score_SMOTE:\n",
    "                        max_score_SMOTE = score_mean2\n",
    "                        best_params_SMOTE = params\n",
    "\n",
    "print(\"Best Parameters for SMOTE dataset:\")\n",
    "print(best_params_SMOTE)\n",
    "print(\"Average Accuracy:\", max_score_SMOTE)\n",
    "f1_score_final2 = 0.0\n",
    "prc_auc_final2 = 0.0\n",
    "roc_auc_final2 = 0.0\n",
    "y_test_all2 = []\n",
    "y_pred_proba_all2 = []\n",
    "\n",
    "for train_index, test_index in skf.split(x_train2, y_train2):\n",
    "    x_train_fold2, x_val_fold2 = x_train2[train_index], x_train2[test_index]\n",
    "    y_train_fold2, y_val_fold2 = y_train2[train_index], y_train2[test_index]\n",
    "    \n",
    "    y_train_fold2 = np.ravel(y_train_fold2)\n",
    "    \n",
    "    final_forest_SMOTE = RandomForestClassifier(**best_params_SMOTE)\n",
    "    final_forest_SMOTE.fit(x_train_fold2, y_train_fold2)\n",
    "    y_pred_final_SMOTE = final_forest_SMOTE.predict_proba(x_val_fold2)[:, 1]  # Predict probabilities\n",
    "    \n",
    "    y_test_all2.extend(y_val_fold2)\n",
    "    y_pred_proba_all2.extend(y_pred_final_SMOTE)\n",
    "    \n",
    "    f1_final_SMOTE = f1_score(y_val_fold2, (y_pred_final_SMOTE > 0.5).astype(int))\n",
    "    f1_score_final2 += f1_final_SMOTE\n",
    "    \n",
    "    precision2, recall2, _ = precision_recall_curve(y_val_fold2.ravel(), y_pred_final_SMOTE.ravel())\n",
    "    prc_auc2 = average_precision_score(y_val_fold2.ravel(), y_pred_final_SMOTE.ravel())\n",
    "    prc_auc_final2 += prc_auc2\n",
    "    \n",
    "fpr_final2, tpr_final2, _ = roc_curve(y_test_all2, y_pred_proba_all2)\n",
    "roc_auc_final2 = roc_auc_score(y_test_all2, y_pred_proba_all2)\n",
    "\n",
    "f1_score_final2 /= skf.n_splits\n",
    "prc_auc_final2 /= skf.n_splits\n",
    "\n",
    "conf_matrix_final2 = confusion_matrix(y_test_all2, (np.array(y_pred_proba_all2) > 0.5).astype(int))\n",
    "\n",
    "tpr_final_value2 = conf_matrix_final2[1, 1] / (conf_matrix_final2[1, 1] + conf_matrix_final2[1, 0])\n",
    "fpr_final_value2 = conf_matrix_final2[0, 1] / (conf_matrix_final2[0, 1] + conf_matrix_final2[0, 0])\n",
    "\n",
    "print(\"F1 Score for SMOTE dataset:\", f1_score_final2)\n",
    "print(\"Precision for SMOTE dataset: \", precision2)\n",
    "print(\"Recall for SMOTE dataset:\", recall2)\n",
    "print(\"Precision-Recall AUC for SMOTE dataset:\", prc_auc_final2)\n",
    "print(\"ROC AUC for SMOTE dataset:\", roc_auc_final2)\n",
    "print(\"TPR for SMOTE roc:\", tpr_final2)\n",
    "print(\"FPR for SMOTE roc:\", fpr_final2)\n",
    "print(\"TPR for SMOTE:\", tpr_final_value2)\n",
    "print(\"FPR for SMOTE:\", fpr_final_value2)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_final2, tpr_final2, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc_final2)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve for SMOTE')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('/kaggle/working/roc_curve_smote.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recall2, precision2, color='blue', lw=2, label='Precision-Recall curve (AUC = %0.2f)' % prc_auc_final2)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve for SMOTE')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('/kaggle/working/precision_recall_curve_smote.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json   \n",
    "data = {\n",
    "    \"Average F1 Score\": f1_score_final2, \n",
    "    \"Precision\": precision2.tolist(), \n",
    "    \"Recall\": recall2.tolist(), \n",
    "    \"Average True Positive Rate\": tpr_final_value2, \n",
    "    \"Average False Positive Rate\": fpr_final_value2, \n",
    "    \"Average ROC AUC\": roc_auc_final2, \n",
    "    \"Average PRC AUC\": prc_auc_final2,\n",
    "    \"TPR Array\" : tpr_final2.tolist(),\n",
    "    \"FPR Array\" : fpr_final2.tolist(),\n",
    "}\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"/kaggle/working/Random Forest - Synthetic Dataset - SMOTE.json\"\n",
    "\n",
    "# Write the data to a JSON file\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(data, json_file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
