{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Activation, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_recall_curve, roc_curve, confusion_matrix, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Load dataset from CSV\n",
    "dataFileName = '/kaggle/input/concatenated-pca/concatenated_data_Amazon_PCA.csv'  # Update this path to your CSV file\n",
    "# Load the dataset\n",
    "dataset = np.genfromtxt(dataFileName, delimiter=',', skip_header=1)  # Assuming there is a header to skip\n",
    "features = dataset[:, :-1]  # Omit the first two columns and use all but the last column for features\n",
    "labels = dataset[:, -1]  # Use the last column as the label\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "\n",
    "# Reshape after scaling if using CNN\n",
    "x_train = x_train.reshape(-1, 1, x_train.shape[1], 1)\n",
    "x_val = x_val.reshape(-1, 1, x_val.shape[1], 1)\n",
    "\n",
    "# Model setup\n",
    "input_shape = x_train.shape[1:]  # Ensure this matches the shape expected by your network, adding channels if needed\n",
    "num_classes = 1  # Binary classification\n",
    "\n",
    "# Define a modified AlexNet model with adjusted pooling size\n",
    "def alexnet_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(96, (3, 3), strides=(2, 2), activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(1, 2))(x)  # Adjusted pooling size\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(1, 2))(x)  # Adjusted pooling size\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='sigmoid')(x)\n",
    "    return Model(inputs=inputs, outputs=x)\n",
    "\n",
    "# Initialize the model\n",
    "input_shape = (1, x_train.shape[2], 1)  # Adjust based on actual reshaped input size\n",
    "alexnet = alexnet_model(input_shape=input_shape)\n",
    "alexnet.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath='alexnet_model_real_life_PCA.h5', verbose=1, save_best_only=True),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=10)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "epochs = 30  # Adjust as needed\n",
    "history = alexnet.fit(x_train, y_train, batch_size=64, epochs=epochs, validation_data=(x_val, y_val), shuffle=True, callbacks=callbacks)\n",
    "\n",
    "# Save the final model\n",
    "alexnet.save('alexnet_model_real_life_PCA.h5')\n",
    "\n",
    "# Save training history\n",
    "with open('alexnet_training_history_real_life_PCA.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "scores = alexnet.evaluate(x_val, y_val, verbose=1)\n",
    "y_preds = (alexnet.predict(x_val) > 0.5).astype(int)\n",
    "y_pred_binary = (y_preds > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_val.ravel(), y_preds.ravel(), average='macro')\n",
    "tn, fp, fn, tp = confusion_matrix(y_val.ravel(), y_pred_binary.ravel()).ravel()\n",
    "tpr1 = tp / (tp + fn)\n",
    "fpr1 = fp / (fp + tn)\n",
    "cm = confusion_matrix(y_val.ravel(), y_preds.ravel())\n",
    "\n",
    "# Calculate ROC and Precision-Recall curves\n",
    "fpr, tpr, _ = roc_curve(y_val.ravel(), y_preds.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "precision, recall, _ = precision_recall_curve(y_val.ravel(), y_preds.ravel())\n",
    "prc_auc = auc(recall, precision)\n",
    "\n",
    "# Save metrics and curves\n",
    "metrics = {\n",
    "    'Validation Loss': scores[0],\n",
    "    'Validation Accuracy': scores[1],\n",
    "    'F1 Score': f1,\n",
    "    'True Positive Rate' : tpr1,\n",
    "    'False Positive Rate' : fpr1,\n",
    "    'Confusion Matrix': cm.tolist(),\n",
    "    'ROC AUC': roc_auc,\n",
    "    'PRC AUC': prc_auc,\n",
    "    'FPR Array': fpr.tolist(),\n",
    "    'TPR Array': tpr.tolist(),\n",
    "    'Precision Array': precision.tolist(),\n",
    "    'Recall Array': recall.tolist()\n",
    "}\n",
    "with open('alexnet_evaluation_metrics_real_life_PCA.json', 'w') as file:\n",
    "    json.dump(metrics, file)\n",
    "\n",
    "# Plot and save ROC Curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('alexnet_roc_curve_real_life_PCA.png')\n",
    "\n",
    "# Plot and save Precision-Recall Curve\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, color='blue', lw=2, label='Precision-Recall curve (area = %0.2f)' % prc_auc)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('alexnet_precision_recall_curve_real_life_PCA.png')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
