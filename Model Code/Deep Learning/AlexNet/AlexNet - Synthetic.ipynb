{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_recall_curve, roc_curve, confusion_matrix, auc\n",
    "\n",
    "# Load dataset from CSV\n",
    "dataFileName = '/kaggle/input/randomoutput/output-2.csv'  # Adjust path as necessary\n",
    "try:\n",
    "    raw_dataset = np.genfromtxt(dataFileName, delimiter=',', dtype=str)\n",
    "    dataset = raw_dataset[:, 2:]  # Adjust indexing based on your CSV structure\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load or parse the CSV file. Error: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_dataset, val_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a modified AlexNet model\n",
    "def alexnet_model(input_shape, num_classes=4):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(96, (3, 3), strides=(2, 2), activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='sigmoid')(x)\n",
    "    return Model(inputs=inputs, outputs=x)\n",
    "\n",
    "# Preprocess data\n",
    "metadata = train_dataset.shape[1] - 4\n",
    "x_train = to_categorical(train_dataset[:, :metadata])\n",
    "x_val = to_categorical(val_dataset[:, :metadata])\n",
    "y_train = train_dataset[:, metadata:].astype(int)\n",
    "y_val = val_dataset[:, metadata:].astype(int)\n",
    "\n",
    "# Add an extra dimension\n",
    "x_train = x_train[..., np.newaxis]\n",
    "x_val = x_val[..., np.newaxis]\n",
    "\n",
    "# Model setup\n",
    "input_shape = x_train.shape[1:]\n",
    "model = alexnet_model(input_shape=input_shape)\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath='alexnet_best_synthethic.h5', verbose=1, save_best_only=True),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=10)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "epochs = 30\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=epochs, validation_data=(x_val, y_val), shuffle=True, callbacks=callbacks)\n",
    "\n",
    "# Save the final model and training history\n",
    "model.save('alexnet_final_model_synthethic.h5')\n",
    "with open('alexnet_training_history_synthethic.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "scores = model.evaluate(x_val, y_val, verbose=1)\n",
    "y_preds = (model.predict(x_val) > 0.5).astype(int)\n",
    "y_pred_binary = (y_preds > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_val.ravel(), y_preds.ravel(), average='macro')\n",
    "tn, fp, fn, tp = confusion_matrix(y_val.ravel(), y_pred_binary.ravel()).ravel()\n",
    "tpr1 = tp / (tp + fn)\n",
    "fpr1 = fp / (fp + tn)\n",
    "cm = confusion_matrix(y_val.ravel(), y_preds.ravel())\n",
    "\n",
    "# Calculate ROC and Precision-Recall curves\n",
    "fpr, tpr, _ = roc_curve(y_val.ravel(), y_preds.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "precision, recall, _ = precision_recall_curve(y_val.ravel(), y_preds.ravel())\n",
    "prc_auc = auc(recall, precision)\n",
    "\n",
    "# Save metrics and curves\n",
    "metrics = {\n",
    "    'Validation Loss': scores[0],\n",
    "    'Validation Accuracy': scores[1],\n",
    "    'F1 Score': f1,\n",
    "    'True Positive Rate' : tpr1,\n",
    "    'False Positive Rate' : fpr1,\n",
    "    'Confusion Matrix': cm.tolist(),\n",
    "    'ROC AUC': roc_auc,\n",
    "    'PRC AUC': prc_auc,\n",
    "    'FPR Array': fpr.tolist(),\n",
    "    'TPR Array': tpr.tolist(),\n",
    "    'Precision Array': precision.tolist(),\n",
    "    'Recall Array': recall.tolist()\n",
    "}\n",
    "with open('alexnet_evaluation_metrics_synthethic.json', 'w') as file:\n",
    "    json.dump(metrics, file)\n",
    "\n",
    "# Plot and save ROC Curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('alexnet_roc_curve_synthethic.png')\n",
    "\n",
    "# Plot and save Precision-Recall Curve\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, color='blue', lw=2, label='Precision-Recall curve (area = %0.2f)' % prc_auc)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('alexnet_precision_recall_curve_synthethic.png')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
