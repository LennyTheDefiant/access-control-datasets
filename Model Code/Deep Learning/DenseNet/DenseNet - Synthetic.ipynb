{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation, AveragePooling2D, GlobalAveragePooling2D, Input, concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import f1_score, precision_recall_curve, roc_curve, confusion_matrix, auc\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "debug = True\n",
    "\n",
    "dataFileName = '/kaggle/input/randomoutput/output-2.csv'\n",
    "\n",
    "# Load the dataset using pandas\n",
    "df = pd.read_csv(dataFileName, delimiter=',', header=None, dtype=str)  # Adjust delimiter if necessary\n",
    "\n",
    "# Convert DataFrame to numpy array\n",
    "raw_dataset = df.values\n",
    "\n",
    "# Ensure the dataset is not empty and has the expected dimensions\n",
    "if raw_dataset.ndim != 2:\n",
    "    raise ValueError(\"Dataset loaded is not in the expected 2D format.\")\n",
    "\n",
    "cols = raw_dataset.shape[1]\n",
    "dataset = raw_dataset[:, 2:cols]  # To skip UID RID\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "metadata = cols - 6 \n",
    "x = dataset[:, 0:metadata]\n",
    "y = dataset[:, metadata:cols].astype(int)\n",
    "\n",
    "# Split into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "############### OneHot ENCODING ##############\n",
    "x_train = to_categorical(x_train)\n",
    "x_test = to_categorical(x_test)\n",
    "\n",
    "if debug:\n",
    "    print('Shape of x_train after encoding:', x_train.shape)\n",
    "    print('Shape of x_test after encoding:', x_test.shape)\n",
    "#######################################\n",
    "\n",
    "# Adding an extra dimension to make the input appropriate for DenseNet\n",
    "x_train = x_train[..., np.newaxis]\n",
    "x_test = x_test[..., np.newaxis]\n",
    "\n",
    "if debug:\n",
    "    print('Shape of x_train after adding new dimension:', x_train.shape)\n",
    "    print('Shape of x_test after adding new dimension:', x_test.shape)\n",
    "\n",
    "# Define the DenseNet model\n",
    "def dense_block(x, blocks, growth_rate):\n",
    "    for i in range(blocks):\n",
    "        x = conv_block(x, growth_rate)\n",
    "    return x\n",
    "\n",
    "def transition_block(x, reduction):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(int(K.int_shape(x)[-1] * reduction), 1, use_bias=False, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x)\n",
    "    x = AveragePooling2D(pool_size=2)(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(x, growth_rate):\n",
    "    x1 = BatchNormalization()(x)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Conv2D(4 * growth_rate, 1, use_bias=False, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Conv2D(growth_rate, 3, padding='same', use_bias=False, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x1)\n",
    "    x = concatenate([x, x1])\n",
    "    return x\n",
    "\n",
    "def densenet_model(input_shape, depth, num_classes=4, growth_rate=12, reduction=0.5):\n",
    "    if (depth - 4) % 3 != 0:\n",
    "        raise ValueError('Depth must be 3N + 4')\n",
    "    num_dense_blocks = (depth - 4) // 3\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(2 * growth_rate, (3, 3), padding='same', use_bias=False, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(inputs)\n",
    "    x = dense_block(x, num_dense_blocks, growth_rate)\n",
    "    x = transition_block(x, reduction)\n",
    "    x = dense_block(x, num_dense_blocks, growth_rate)\n",
    "    x = transition_block(x, reduction)\n",
    "    x = dense_block(x, num_dense_blocks, growth_rate)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(num_classes, activation='sigmoid', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Model parameters\n",
    "input_shape = x_train.shape[1:]\n",
    "depth = 22  # Adjust depth as needed\n",
    "model = densenet_model(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-1), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model training\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "y_preds = (model.predict(x_test) > 0.5).astype(int)\n",
    "y_pred_binary = (y_preds > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_test.ravel(), y_preds.ravel(), average='macro')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test.ravel(), y_pred_binary.ravel()).ravel()\n",
    "tpr1 = tp / (tp + fn)\n",
    "fpr1 = fp / (fp + tn)\n",
    "cm = confusion_matrix(y_test.ravel(), y_preds.ravel())\n",
    "\n",
    "# Calculate ROC and Precision-Recall curves\n",
    "fpr, tpr, _ = roc_curve(y_test.ravel(), y_preds.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "precision, recall, _ = precision_recall_curve(y_test.ravel(), y_preds.ravel())\n",
    "prc_auc = auc(recall, precision)\n",
    "\n",
    "# Save metrics and curves\n",
    "metrics = {\n",
    "    'Validation Loss': scores[0],\n",
    "    'Validation Accuracy': scores[1],\n",
    "    'F1 Score': f1,\n",
    "    'True Positive Rate' : tpr1,\n",
    "    'False Positive Rate' : fpr1,\n",
    "    'Confusion Matrix': cm.tolist(),\n",
    "    'ROC AUC': roc_auc,\n",
    "    'PRC AUC': prc_auc,\n",
    "    'FPR Array': fpr.tolist(),\n",
    "    'TPR Array': tpr.tolist(),\n",
    "    'Precision Array': precision.tolist(),\n",
    "    'Recall Array': recall.tolist()\n",
    "}\n",
    "with open('evaluation_metrics_synthethic.json', 'w') as file:\n",
    "    json.dump(metrics, file)\n",
    "\n",
    "# Plot and save ROC Curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roc_curve_synthethic.png')\n",
    "\n",
    "# Plot and save Precision-Recall Curve\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, color='blue', lw=2, label='Precision-Recall curve (area = %0.2f)' % prc_auc)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('precision_recall_curve_synthethic.png')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
