{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation, AveragePooling2D, GlobalAveragePooling2D, Input, concatenate, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import f1_score, precision_recall_curve, roc_curve, confusion_matrix, auc\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "debug = True\n",
    "\n",
    "dataFileName = '/kaggle/input/concatenated-pca/concatenated_data_Amazon_PCA.csv'\n",
    "\n",
    "# Load the dataset using pandas\n",
    "df = pd.read_csv(dataFileName)\n",
    "\n",
    "# Assume the first two columns are not required and the last column is the label\n",
    "x = df.iloc[:, :-1].values \n",
    "y = df.iloc[:, -1].values  \n",
    "\n",
    "# Convert labels to binary format (if not already in binary form)\n",
    "y = y.astype(int)\n",
    "\n",
    "# Split into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# Reshape after scaling if using CNN\n",
    "x_train = x_train.reshape(-1, 1, x_train.shape[1], 1)\n",
    "x_test = x_test.reshape(-1, 1, x_test.shape[1], 1)\n",
    "\n",
    "\n",
    "# Define the DenseNet model\n",
    "def dense_block(x, blocks, growth_rate):\n",
    "    for i in range(blocks):\n",
    "        x = conv_block(x, growth_rate)\n",
    "    return x\n",
    "\n",
    "# Reduce the pooling size in the transition block function\n",
    "def transition_block(x, reduction, pool_size=1):  # Reduce pool size to 1x1 if necessary\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(int(K.int_shape(x)[-1] * reduction), 1, use_bias=False, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x)\n",
    "    if K.int_shape(x)[1] >= pool_size and K.int_shape(x)[2] >= pool_size:\n",
    "        x = AveragePooling2D(pool_size=pool_size)(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(x, growth_rate):\n",
    "    x1 = BatchNormalization()(x)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Conv2D(4 * growth_rate, 1, use_bias=False, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Conv2D(growth_rate, 3, padding='same', use_bias=False, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x1)\n",
    "    x = concatenate([x, x1])\n",
    "    return x\n",
    "\n",
    "def densenet_model(input_shape, depth, num_classes=1, growth_rate=12, reduction=0.5):\n",
    "    if (depth - 4) % 3 != 0:\n",
    "        raise ValueError('Depth must be 3N + 4')\n",
    "    num_dense_blocks = (depth - 4) // 3\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(2 * growth_rate, (3, 3), padding='same', use_bias=False, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(inputs)\n",
    "    x = dense_block(x, num_dense_blocks, growth_rate)\n",
    "    x = transition_block(x, reduction)\n",
    "    x = dense_block(x, num_dense_blocks, growth_rate)\n",
    "    x = transition_block(x, reduction)\n",
    "    x = dense_block(x, num_dense_blocks, growth_rate)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(num_classes, activation='sigmoid', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Model parameters\n",
    "input_shape = x_train.shape[1:]\n",
    "depth = 22  # Adjust depth as needed\n",
    "model = densenet_model(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-1), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model training\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "y_preds = (model.predict(x_test) > 0.5).astype(int)\n",
    "y_pred_binary = (y_preds > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_test.ravel(), y_preds.ravel(), average='macro')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test.ravel(), y_pred_binary.ravel()).ravel()\n",
    "tpr1 = tp / (tp + fn)\n",
    "fpr1 = fp / (fp + tn)\n",
    "cm = confusion_matrix(y_test.ravel(), y_preds.ravel())\n",
    "\n",
    "# Calculate ROC and Precision-Recall curves\n",
    "fpr, tpr, _ = roc_curve(y_test.ravel(), y_preds.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "precision, recall, _ = precision_recall_curve(y_test.ravel(), y_preds.ravel())\n",
    "prc_auc = auc(recall, precision)\n",
    "\n",
    "# Save metrics and curves\n",
    "metrics = {\n",
    "    'Validation Loss': scores[0],\n",
    "    'Validation Accuracy': scores[1],\n",
    "    'F1 Score': f1,\n",
    "    'True Positive Rate' : tpr1,\n",
    "    'False Positive Rate' : fpr1,\n",
    "    'Confusion Matrix': cm.tolist(),\n",
    "    'ROC AUC': roc_auc,\n",
    "    'PRC AUC': prc_auc,\n",
    "    'FPR Array': fpr.tolist(),\n",
    "    'TPR Array': tpr.tolist(),\n",
    "    'Precision Array': precision.tolist(),\n",
    "    'Recall Array': recall.tolist()\n",
    "}\n",
    "with open('evaluation_metrics_real_life_PCA.json', 'w') as file:\n",
    "    json.dump(metrics, file)\n",
    "\n",
    "# Plot and save ROC Curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roc_curve_real_life_PCA.png')\n",
    "\n",
    "# Plot and save Precision-Recall Curve\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, color='blue', lw=2, label='Precision-Recall curve (area = %0.2f)' % prc_auc)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('precision_recall_curve_real_life_PCA.png')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
